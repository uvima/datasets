---
title: 'Series Temporales - ARIMA: madrid_series'
---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(echo = TRUE, fig.align = "center", warning = FALSE, message = FALSE)


# fig.align= 'center para que nos centre todas figuras que se muestran
# warning = FALSE para que no muestre mensajes de warning
# message = FALSE para que no muestre mensajes automáticos cuando carga paquetes y demás en el output
```

# Introducción

## dataset

En este cuaderno vamos a analizar el dataset llamado
[*Madrid.xlsx*](../../../../files/Madrid_series.xlsx).
Este dataset presenta los datos de población de la Comunidad Autónoma de Madrid a 1 de Enero y 1 de Julio de cada año desde 1971. La serie temporal se encuentra desagregada por Sexos, mostrando para Hombres, Mujeres y el total de la población.  El objetivo de este estudio es intentar modelar dichas series mediante un modelo ARIMA.


Concretamente en este dataset tenemos las siguientes variables:

-   **ccaa**: Madrid siempre.
-   **sexo**: Hombres, Mujeres, Total.
-   **fecha**: Fecha correspondiente.
-   **poblacion**: Cifras de población. 



```{r}
#| label: librerias
#| message: false
#| warning: false
# Librerias
```

Cargamos entonces el conjunto de datos:

```{r}
#| label: cargar_datos
data <- readxl::read_excel("../../../../files/madrid_series.xlsx",
  sheet = "Datos", col_types = c(
    "date",
    "numeric", "numeric", "numeric"
  )
)

data$Total <- data$`Pobl. Total`
data$H <- data$`Pobl. Hombres`
data$M <- data$`Pobl. Mujeres`
```




## Descripción del trabajo a realizar

**(Esto irá en la web de explica)** Se pretende ajustar una serie temporal que contiene la población de Madrid mediante un modelo ARIMA. 

   - Explorar patrones en la serie temporal.
   - Ver que la serie sea estacionaria.
   - Aplicar diferenciación si es necesario para estacionarizar la serie.
   - Identificar modelos ARIMA utilizando información de la exploración y funciones ACF y PACF.
   - Ajustar varios modelos ARIMA y seleccionar el mejor según métricas de ajuste.
   - Evaluar la significancia estadística de los coeficientes del modelo ARIMA.
   - Interpretar los coeficientes para comprender su influencia en la serie temporal.


# Análisis Exploratorio (EDA[^1])

[^1]: EDA viene del Inglés *Exploratory Data Analysis* y son los pasos
    relativos en los que se exploran las variables para tener una idea
    de que forma toma el dataset.



```{r}
sum(is.na(data))
```

Por otra parte, para tener una noción general que nos permita describir el conjunto con el que vamos a trabajar, podemos extraer su dimensión, el tipo de variables que contiene o qué valores toma cada una.


```{r}
# Dimensión del conjunto de datos
dim(data)

# Tipo de variables que contiene
str(data)
```
Vemos que estas variables (a excepción de las CCAA) son todas de tipo numérico, y además, podemos obtener información como la media, desviación típica, los cuartiles y el histograma de cada una.


# ARIMA (AutoRegressive Integrated Moving Average)

## Introducción


El modelo ARIMA es uno de los modelos más comunes y poderosos para el análisis de series temporales. Se utiliza para modelar y predecir datos que exhiben comportamientos de tendencia y estacionalidad.

- **Componentes del modelo ARIMA:**
    - **AR (Auto-regresivo):** Representa la relación entre una observación actual y un número determinado de observaciones anteriores (retardos). **p** es el componente autoregresivo, que indica cuántas observaciones pasadas influyen en la observación actual. Para determinar el valor de p, se puede utilizar el gráfico de la función de autocorrelación parcial (PACF) de la serie diferenciada. Las barras que se salen significativamente del intervalo de confianza pueden indicar el orden de P que debería considerarse. Se recomienda ser conservador y elegir un número reducido de los valores más prominentes.
    - **I (Integrated):**.  Representa el número de diferencias necesarias para hacer estacionaria la serie temporal. **d** es el número de diferenciaciones necesarias para hacer que la serie sea estacionaria. Esto se determina mediante pruebas estadísticas como el test de Dickey-Fuller aumentado (ADF test). Es importante tener cuidado de no sobrediferenciar la serie, lo que se puede observar en el gráfico de la función de autocorrelación (ACF) si los valores comienzan a ser negativos rápidamente.
    
    - **MA (Media Móvil):** Representa la relación entre una observación actual y un error de predicción residual de observaciones anteriores. **q** es el componente de media móvil, que indica cuántos términos de los residuos anteriores influyen en la observación actual. Para determinar el valor de q, se utiliza el gráfico de la función de autocorrelación (ACF) de la serie diferenciada. Los términos MA son esencialmente errores de pronóstico retrasados, y el ACF muestra cuántos términos MA se necesitan para eliminar la autocorrelación en la serie estacionaria. Se sugiere seleccionar tantos términos MA como los lags que estén significativamente por encima del intervalo de confianza.

Si la serie está ligeramente por debajo del nivel de diferenciación adecuado (subdiferenciada), se pueden agregar uno o más términos de AR adicionales. Por otro lado, si la serie está sobrediferenciada, se puede considerar agregar términos MA adicionales para mejorar el modelo.


```{r}
#| echo: false
# Es importante recordar que estos parámetros (P, D, Q) se seleccionan con base en la interpretación de los gráficos ACF y PACF, así como en la observación del comportamiento de la serie temporal. Experimentar con diferentes configuraciones y ajustar el modelo según sea necesario es una parte crucial del proceso de modelado de series temporales.
```













Vamos a cargar los datos en un obejto adecuado para su análisis
```{r}
# Convertir el vector en una serie temporal

# Madrid
tss <- stats::ts(rev(data$Total), start = 1971, frequency = 2)
tss_h <- stats::ts(rev(data$H), start = 1971, frequency = 2)
tss_m <- stats::ts(rev(data$M), start = 1971, frequency = 2)


plot(decompose(tss))
```

**Análisis Descriptivo:**
   Podemos realizar un análisis descriptivo básico para comprender mejor la serie temporal.

   R
```{r}
summary(tss)
# Poblacion de ambos sexos
plot(tss, main = "IPC Mensual desde 2005")
legend("topright", legend = c("Total"), col = "black", lty = 1)

# Poblacion de hombres y de mujeres
plot(tss_h, main = "IPC Mensual desde 2005", col = "red", ylim = c(min(tss_h, tss_m), max(tss_h, tss_m)))
lines(tss_m, col = "blue")
legend("topright", legend = c("Hombres", "Mujeres"), col = c("red", "blue"), lty = 1)
```


Lo primero de todo destacar que la serie no tiene picos internos luego no parece tener una componente estacional dentro del año. Esto es comprensible puesto que la población no tiene por que aumentar en determinado mes del año y disminuir en otro mes de manera regular al final de los años. Es por ello que no vamos a modelar ningún componente relacionado con la estacionalidad.



## Modelo
Para ajustar un modelo ARIMA a los datos, primero necesitamos identificar los parámetros del modelo (p, d, q).


Se dice que una serie es estacionaria cuando su media, varianza y autocovarianza son invariantes en el tiempo.
Para realizar un modelo ARIMA, la serie temporal debe ser estacionaria. Para conseguir esta estacionariedad, la diferenciaremos.

```{r}
t1 <- diff(tss, differences = 1)
t2 <- diff(tss, differences = 2)
t3 <- diff(tss, differences = 3)


par(mfrow = c(3, 1), mar = c(3, 3, 3, 2) + 0.1)
plot(t1)
plot(t2)
plot(t3)

# TEST para ver estacionaridad
# H0= NO es estacionaria
tseries::adf.test(t1, alternative = "stationary")
tseries::adf.test(t2, alternative = "stationary")
tseries::adf.test(t3, alternative = "stationary")
```

Al trazar la serie diferenciada de orden 3, ya vemos un patron oscilante alrededor de 0, sin una tendencia fuerte visible. Esto sugiere que la diferenciacion es suficiente y debe incluirse en el modelo. Además el test de estacionaridad ya lo pasa.



A continuación, los picos en rezagos particulares de la serie diferenciada pueden ayudar a informar la elección de p o q para nuestro modelo. Nos interesan los de orden 3 ya que son los del orden de diferenciación que vamos a tomar. 
```{r}
forecast::Acf(t1, main = "ACF para la serie diferenciada 1 vez", lag.max = 50, ylim = c(-1, 1))
forecast::Acf(t2, main = "ACF para la serie diferenciada 2 vez", lag.max = 50, ylim = c(-1, 1))
forecast::Acf(t3, main = "ACF para la serie diferenciada 3 vez", lag.max = 50, ylim = c(-1, 1))
```

En el gráfico de ACF vemos que hay 2 o 3 barras que se salen notablemente del límite deseado, luego tomariamos como q= 2, o 3.




```{r}
forecast::Pacf(t1, main = "ACF para la serie diferenciada 1 vez", lag.max = 50, ylim = c(-1, 1))
forecast::Pacf(t2, main = "ACF para la serie diferenciada 2 vez", lag.max = 50, ylim = c(-1, 1))
forecast::Pacf(t3, main = "ACF para la serie diferenciada 3 vez", lag.max = 50, ylim = c(-1, 1))
```


En el gráfico de PACF vemos que hay  1 o 2 barras que se salen  del límite deseado, luego tomariamos como p= 1.



```{r}
library(forecast)

# Ajustar el modelo ARIMA

# p, d,  q
arima_model1 <- arima(tss, order = c(1, 3, 2))
arima_model_h <- arima(tss_h, order = c(1, 3, 2))
#arima_model_m <- arima(tss_m, order = c(1, 3, 2))

summary(arima_model1)




# Diagnóstico del modelo
checkresiduals(arima_model1)



# H0: no hay autocorrelación residual en los residuos del model 
# Queremos ver que se prueba H0
Box.test(residuals(arima_model1), type = "Ljung-Box")

# Aceptamos H0 puesto que es >0.05



```

La media de los residuos es cercana a cero y no existe correlación significativa en las series de residuos. La serie temporal de los residuos muestra que la variación de los residuos se mantiene prácticamente igual en todos los datos históricos, quitando los últimos años y por lo tanto la varianza residual podría tratarse como constante. Esto también se puede ver en el histograma de residuos. El histograma sugiere que los residuos pueden no ser normales: la cola derecha parece demasiado larga, incluso cuando ignoramos el valor atípico. En consecuencia, los pronósticos de este método probablemente serán bastante buenos, pero los intervalos de predicción que se calculan suponiendo una distribución normal pueden ser inexactos.




Ahora vamos a probar otro modelo con los siguientes parámetros (1, 1, 0) y posteriormente los compararemos.

```{r}
arima_model2 <- arima(tss, order = c(1, 1, 0))
summary(arima_model2)
```





Existe una función que permite identificar los parámetros de manera automática.
```{r}
# Identificar los parámetros del modelo ARIMA de manera automática
auto.arima(tss)
```


```{r}
#Dibujamos las predicciones ahora
tss_m <- stats::ts(rev(data$Total), start = 1971, frequency = 2, end = 2018)
arima_model1b <- arima(tss_m, order = c(2, 3, 1))
arima_model2b <- arima(tss_m, order = c(1, 1, 0))
# Predicciones utilizando arima_model1
pred1 <- predict(arima_model1b, n.ahead = 6)

# Predicciones utilizando arima_model2
pred2 <- predict(arima_model2b, n.ahead = 6)

upper1 <- pred1$pred + 1.96 * pred1$se
lower1 <- pred1$pred - 1.96 * pred1$se
upper2 <- pred2$pred + 1.96 * pred2$se
lower2 <- pred2$pred - 1.96 * pred2$se
# Gráfico con los datos originales y las predicciones de los modelos
plot(tss,
  xlim = c(1971, 2021 + 5), ylim = c(min(tss, pred1$pred, pred2$pred), max(tss, pred1$pred, pred2$pred)),
  xlab = "Fecha", ylab = "Valor", main = "Comparación de Predicciones ARIMA"
)
lines(tss, col = "blue", lwd = 2) # Serie original en azul
points(pred1$pred, col = "red", pch = 16, cex = 0.5) # Predicciones con arima_model1 en rojo
points(pred2$pred, col = "green", pch = 16, cex = 0.5) # Predicciones con arima_model2 en verde
legend("bottomright", legend = c("Original", "ARIMA Modelo 1", "ARIMA Modelo 2"), col = c("blue", "red", "green"), lty = 1)

lines(upper1, col = "red", lty = "solid")
lines(lower1, col = "red", lty = "solid")
lines(upper2, col = "green", lty = "solid")
lines(lower2, col = "green", lty = "solid")
```

```{r}
# Función automática autoplot()
autoplot(forecast(arima_model1b))
```




Vemos que el primer modelo propuesto tiene menor AIC y menor MRSE luego lo podríamos considerar como mejor.
```{r}
summary(arima_model1)
summary(arima_model2)
```




# Conclusiones

Las nuevas componentes han permitido analizar las características más destacadas de las comunidades autónomas en términos del mercado hipotecario, el riesgo hipotecario, la estabilidad financiera y la demanda futura.
